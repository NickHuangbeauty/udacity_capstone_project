{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Checks\n",
    "- Check data is empty or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from s3path import S3Path\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ***** Access AWS Cloud configure ************\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('/Users/oneforall_nick/workspace/Udacity_capstone_project/cfg/dl.cfg'))\n",
    "\n",
    "aws_access_key = config[\"ACCESS\"][\"AWS_ACCESS_KEY_ID\"]\n",
    "aws_secret_access_key = config[\"ACCESS\"][\"AWS_SECRET_ACCESS_KEY\"]\n",
    "aws_token = config[\"ACCESS\"][\"AWS_TOKEN\"]\n",
    "dest_aws_s3_bucket = config[\"S3\"][\"DEST_S3_BUCKET\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_bucket_path = S3Path(f\"{dest_aws_s3_bucket}/dimension_table\")\n",
    "fact_bucket_path = S3Path(f\"{dest_aws_s3_bucket}/fact_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: df_immigration_personal, Count data objects: 114\n",
      "Data: imm_address, Count data objects: 9\n",
      "Data: imm_city_res_label, Count data objects: 9\n",
      "Data: imm_destination_city, Count data objects: 9\n",
      "Data: imm_travel_code, Count data objects: 6\n",
      "Data: imm_visa, Count data objects: 5\n",
      "Data: immigration_main_information, Count data objects: 1\n",
      "Data: news_article_data, Count data objects: 6305\n",
      "Data: us_cities_demographics_data, Count data objects: 301\n"
     ]
    }
   ],
   "source": [
    " # ******** Dimension Tables ********\n",
    "# Data Object Name: df_immigration_personal\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'df_immigration_personal']:\n",
    "    print(\n",
    "        f\"Data: df_immigration_personal, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "# Data Object Name: imm_address\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'imm_address']:\n",
    "    print(f\"Data: imm_address, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: imm_city_res_label\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'imm_city_res_label']:\n",
    "    print(f\"Data: imm_city_res_label, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: imm_destination_city\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'imm_destination_city']:\n",
    "    print(f\"Data: imm_destination_city, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: imm_travel_code\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'imm_travel_code']:\n",
    "    print(f\"Data: imm_travel_code, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: imm_visa\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'imm_visa']:\n",
    "    print(f\"Data: imm_visa, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: immigration_main_information\n",
    "if data_list := [str(path_1) for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir(\n",
    ") if str(path_1).split('/')[-2] == 'immigration_main_information' and path_1.is_dir()]:\n",
    "    print(\n",
    "        f\"Data: immigration_main_information, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: news_article_data\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'news_article_data']:\n",
    "    print(\n",
    "        f\"Data: news_article_data, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n",
    "\n",
    "\n",
    "# Data Object Name: us_cities_demographics_data\n",
    "if data_list := [str(path_1).split('/')[-1] for path in dim_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if str(path_1).split('/')[-2] in 'us_cities_demographics_data']:\n",
    "    print(\n",
    "        f\"Data: us_cities_demographics_data, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: notification, Count data objects: 2\n"
     ]
    }
   ],
   "source": [
    " # ******** Fact Tables ********\n",
    "# Data Object Name: notification\n",
    "if data_list := [str(path_1).split('/')[-1] for path in fact_bucket_path.iterdir() if path.is_dir() for path_1 in path.iterdir() if path_1.is_dir() if str(path_1).split('/')[-2] in 'notification']:\n",
    "    print(f\"Data: notification, Count data objects: {len(data_list)}\")\n",
    "else:\n",
    "    raise ValueError(\"This table does not contain data!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Schema - Dimension Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 765 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   imm_per_cic_id         765 non-null    string  \n",
      " 1   imm_person_gender      651 non-null    string  \n",
      " 2   imm_visatype           765 non-null    string  \n",
      " 3   imm_person_birth_year  765 non-null    category\n",
      "dtypes: category(1), string(3)\n",
      "memory usage: 24.8 KB\n"
     ]
    }
   ],
   "source": [
    " # ***** df_immigration_personal column schema and data type *****\n",
    "partition_filter = lambda x: x[\"imm_person_birth_year\"] == \"2016\"\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/df_immigration_personal/\", dataset=True, partition_filter=partition_filter)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   code_of_imm_address   55 non-null     string\n",
      " 1   value_of_imm_address  55 non-null     string\n",
      "dtypes: string(2)\n",
      "memory usage: 1.3 KB\n"
     ]
    }
   ],
   "source": [
    " # ***** imm_address column schema and data type *****\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/imm_address/\", dataset=True)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7 entries, 0 to 0\n",
      "Data columns (total 3 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   col_of_imm_cntyl                  7 non-null      Int32 \n",
      " 1   value_of_imm_cntyl                7 non-null      string\n",
      " 2   value_of_imm_cntyl_organizations  7 non-null      string\n",
      "dtypes: Int32(1), string(2)\n",
      "memory usage: 203.0 bytes\n"
     ]
    }
   ],
   "source": [
    " # ***** imm_city_res_label column schema and data type *****\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/imm_city_res_label/\", dataset=True)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 596 entries, 0 to 77\n",
      "Data columns (total 3 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   code_of_imm_destination_city         596 non-null    string\n",
      " 1   value_of_imm_destination_city        596 non-null    string\n",
      " 2   value_of_alias_imm_destination_city  596 non-null    string\n",
      "dtypes: string(3)\n",
      "memory usage: 18.6 KB\n"
     ]
    }
   ],
   "source": [
    " # ***** imm_destination_city column schema and data type *****\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/imm_destination_city/\", dataset=True)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   code_of_imm_travel_code   0 non-null      Int32 \n",
      " 1   value_of_imm_travel_code  4 non-null      string\n",
      "dtypes: Int32(1), string(1)\n",
      "memory usage: 84.0 bytes\n"
     ]
    }
   ],
   "source": [
    " # ***** imm_travel_code column schema and data type *****\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/imm_travel_code/\", dataset=True)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   code_of_imm_visa   3 non-null      Int32 \n",
      " 1   value_of_imm_visa  3 non-null      string\n",
      "dtypes: Int32(1), string(1)\n",
      "memory usage: 63.0 bytes\n"
     ]
    }
   ],
   "source": [
    " # ***** imm_visa column schema and data type *****\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/imm_visa/\", dataset=True)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3096313 entries, 0 to 10320\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Dtype   \n",
      "---  ------              -----   \n",
      " 0   imm_main_cic_id     Int32   \n",
      " 1   imm_cntyl           Int32   \n",
      " 2   imm_visa            Int32   \n",
      " 3   imm_port            string  \n",
      " 4   imm_arrival_date    object  \n",
      " 5   imm_departure_date  object  \n",
      " 6   imm_model           Int32   \n",
      " 7   imm_address         string  \n",
      " 8   imm_airline         string  \n",
      " 9   imm_flight_no       string  \n",
      " 10  imm_year            category\n",
      " 11  imm_month           category\n",
      "dtypes: Int32(4), category(2), object(2), string(4)\n",
      "memory usage: 230.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# ***** immigration_main_information column schema and data type *****\n",
    "def partition_filter(x): return x[\"imm_year\"] == \"2016\"\n",
    "\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/immigration_main_information/\",\n",
    "                         dataset=True, partition_filter=partition_filter)\n",
    "dfs.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41 entries, 0 to 0\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   news_cord_uid      41 non-null     string  \n",
      " 1   news_source        41 non-null     string  \n",
      " 2   news_title         41 non-null     string  \n",
      " 3   news_licence       41 non-null     string  \n",
      " 4   news_abstract      36 non-null     string  \n",
      " 5   news_authors       41 non-null     string  \n",
      " 6   news_url           41 non-null     string  \n",
      " 7   news_publish_time  41 non-null     category\n",
      "dtypes: category(1), string(7)\n",
      "memory usage: 2.7 KB\n"
     ]
    }
   ],
   "source": [
    " # ***** news_article_data column schema and data type *****\n",
    "partition_filter = lambda x: \"2016-01-01\" <= x[\"news_publish_time\"] <= \"2016-01-02\"\n",
    "\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/news_article_data/\", dataset=True, partition_filter=partition_filter)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2891 entries, 0 to 8\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   cidemo_city              2891 non-null   string \n",
      " 1   cidemo_state             2891 non-null   string \n",
      " 2   cidemo_median_age        2891 non-null   float32\n",
      " 3   cidemo_total_population  2891 non-null   Int32  \n",
      " 4   cidemo_state_code        2891 non-null   string \n",
      " 5   cidemo_count             2891 non-null   Int32  \n",
      " 6   cidemo_id                2891 non-null   Int64  \n",
      "dtypes: Int32(2), Int64(1), float32(1), string(3)\n",
      "memory usage: 155.3 KB\n"
     ]
    }
   ],
   "source": [
    " # ***** us_cities_demographics_data column schema and data type *****\n",
    "dfs = wr.s3.read_parquet(path=\"s3://destetlbucket/dimension_table/us_cities_demographics_data/\", dataset=True)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Schema - Fact Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ***** notification column schema and data type *****\n",
    "partition_filter = lambda x: x[\"news_publish_time\"] == \"2016-04-01\"\n",
    "\n",
    "dfs = wr.s3.read_parquet(\n",
    "    path=\"s3://destetlbucket/fact_table/notification/\", dataset=True, partition_filter=partition_filter)\n",
    "dfs.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f40c152a15a669d798eb1ad4e6f345bdd77350f6745bfc8751a72382d50440f0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nick_udacity_capstone_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
