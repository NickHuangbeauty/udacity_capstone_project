{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, monotonically_increasing_id\n",
    "from pyspark.sql.types import (StructType,\n",
    "                               StructField,\n",
    "                               StringType,\n",
    "                               IntegerType,\n",
    "                               DoubleType,\n",
    "                               FloatType,\n",
    "                               LongType,\n",
    "                               TimestampType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 00:04:47 WARN Utils: Your hostname, OneForAll-NickdeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.101 instead (on interface en0)\n",
      "22/05/27 00:04:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/libexec/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/27 00:04:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    appName(\"data_spark_on_emr\").\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.101:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>data_spark_on_emr</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fac943e1e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/oneforall_nick/workspace/Udacity_capstone_project/aws_emr_steps/practice_and_learn_aws_emr_process.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneforall_nick/workspace/Udacity_capstone_project/aws_emr_steps/practice_and_learn_aws_emr_process.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m# Stop spark session if I don't need it.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oneforall_nick/workspace/Udacity_capstone_project/aws_emr_steps/practice_and_learn_aws_emr_process.ipynb#ch0000003?line=1'>2</a>\u001b[0m spark\u001b[39m.\u001b[39;49mstop()\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py:798\u001b[0m, in \u001b[0;36mSparkSession.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py?line=794'>795</a>\u001b[0m \u001b[39m\"\"\"Stop the underlying :class:`SparkContext`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py?line=795'>796</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py?line=796'>797</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m \u001b[39mimport\u001b[39;00m SQLContext\n\u001b[0;32m--> <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py?line=797'>798</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sc\u001b[39m.\u001b[39;49mstop()\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py?line=798'>799</a>\u001b[0m \u001b[39m# We should clean the default session up. See SPARK-23228.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/session.py?line=799'>800</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mSparkSession\u001b[39m.\u001b[39mclearDefaultSession()\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py:465\u001b[0m, in \u001b[0;36mSparkContext.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=462'>463</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_jsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=463'>464</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=464'>465</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsc\u001b[39m.\u001b[39;49mstop()\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=465'>466</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JError:\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=466'>467</a>\u001b[0m         \u001b[39m# Case: SPARK-18523\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=467'>468</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=468'>469</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mUnable to cleanly shutdown Spark JVM process.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=469'>470</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m It is possible that the process has crashed,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=470'>471</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m been killed or may also be in a zombie state.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=471'>472</a>\u001b[0m             \u001b[39mRuntimeWarning\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/context.py?line=472'>473</a>\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1295'>1296</a>\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1297'>1298</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1298'>1299</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1299'>1300</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1300'>1301</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1302'>1303</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1303'>1304</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1304'>1305</a>\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1306'>1307</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1030'>1031</a>\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1031'>1032</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1032'>1033</a>\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1033'>1034</a>\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/java_gateway.py?line=1034'>1035</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py?line=472'>473</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py?line=473'>474</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py?line=474'>475</a>\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py?line=475'>476</a>\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py?line=476'>477</a>\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/site-packages/py4j/clientserver.py?line=477'>478</a>\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/socket.py?line=701'>702</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/socket.py?line=702'>703</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/socket.py?line=703'>704</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/socket.py?line=704'>705</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/udacity_capstone_project/lib/python3.9/socket.py?line=705'>706</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stop spark session if I don't need it.\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.parquet.binaryAsString', 'true'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '\"-Dio.netty.tryReflectionSetAccessible=true\"'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.driver.host', '10.0.0.101'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/Users/oneforall_nick/workspace/Udacity_capstone_project/aws_emr_steps/spark-warehouse'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '\"-Dio.netty.tryReflectionSetAccessible=true\"'),\n",
       " ('spark.driver.port', '49413'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.name', 'data_spark_on_emr'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.app.startTime', '1653581088617'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1653581090109'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark session setting configuration\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ALL DATA AND SAVE TO simulation data file, and then analysis those data in spark.\n",
    "# ****** Read data from local file system(be a s3) to spark DataFrame ******\n",
    "# All data format will be saved as a parquet file.\n",
    "\n",
    "# file path: data >> immigration_data\n",
    "# There are three tables: immigration_table, immigration_personal_table and immigration_label_table\n",
    "# ***immigration_table, immigration_personal_table and immigration_label_table schema***\n",
    "\"\"\"\"Table: immigration_main_information schema\n",
    "pk: cicid -> imm_main_cic_id\n",
    "1. i94yr  -> imm_year\n",
    "2. i94mon -> imm_month\n",
    "3. i94citi&i94res -> imm_citi_res -> imm_cntyl\n",
    "4. i94visa -> imm_visa\n",
    "    three categories:\n",
    "        1 = Business\n",
    "        2 = Pleasure\n",
    "        3 = Student\n",
    "5. i94port -> imm_port\n",
    "6. arrdate -> imm_arrival_date:\n",
    "7. i94mode -> imm_model:\n",
    "    four categories:\n",
    "        1 = 'Air'\n",
    "\t    2 = 'Sea'\n",
    "\t    3 = 'Land'\n",
    "\t    9 = 'Not reported'\n",
    "8. i94addr -> imm_address\n",
    "    ex: 'AL'='ALABAMA'\n",
    "9. airline -> imm_airline\n",
    "10 fltno -> imm_flight_no\n",
    "    schema: StringType()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Table: immigration_personal schema -> According to this person data that I will make a core data table to display notifications information.\n",
    "pk: cicid -> imm_per_cic_id\n",
    "    schema: StringType()\n",
    "1. biryear -> imm_person_birth_year\n",
    "    schema: IntegerType()\n",
    "2. gender -> imm_person_gender\n",
    "    schema: StringType()\n",
    "3. visatype -> imm_person_visa_type\n",
    "    schema: StringType()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Table: immigration_label schema\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_full_text</th>\n",
       "      <th>full_text_file</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vho70jcx</td>\n",
       "      <td>f056da9c64fbf00a4645ae326e8a4339d015d155</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>SIANN: Strain Identification by Alignment to N...</td>\n",
       "      <td>10.1101/001727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Next-generation sequencing is increasingly bei...</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>Samuel Minot; Stephen D Turner; Krista L Ternu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>biorxiv_medrxiv</td>\n",
       "      <td>https://doi.org/10.1101/001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i9tbix2v</td>\n",
       "      <td>daf32e013d325a6feb80e83d15aabc64a48fae33</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Spatial epidemiology of networked metapopulati...</td>\n",
       "      <td>10.1101/003889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>An emerging disease is one infectious epidemic...</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>Lin WANG; Xiang Li</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>biorxiv_medrxiv</td>\n",
       "      <td>https://doi.org/10.1101/003889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62gfisc6</td>\n",
       "      <td>f33c6d94b0efaa198f8f3f20e644625fa3fe10d2</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Sequencing of the human IG light chain loci fr...</td>\n",
       "      <td>10.1101/006866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Germline variation at immunoglobulin gene (IG)...</td>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>Corey T Watson; Karyn Meltz Steinberg; Tina A ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>biorxiv_medrxiv</td>\n",
       "      <td>https://doi.org/10.1101/006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>058r9486</td>\n",
       "      <td>4da8a87e614373d56070ed272487451266dce919</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Bayesian mixture analysis for metagenomic comm...</td>\n",
       "      <td>10.1101/007476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Deep sequencing of clinical samples is now an ...</td>\n",
       "      <td>2014-07-25</td>\n",
       "      <td>Sofia Morfopoulou; Vincent Plagnol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>biorxiv_medrxiv</td>\n",
       "      <td>https://doi.org/10.1101/007476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wich35l7</td>\n",
       "      <td>eccef80cfbe078235df22398f195d5db462d8000</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Mapping a viral phylogeny onto outbreak trees ...</td>\n",
       "      <td>10.1101/010389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biorxiv</td>\n",
       "      <td>Developing methods to reconstruct transmission...</td>\n",
       "      <td>2014-11-11</td>\n",
       "      <td>Stephen P Velsko; Jonathan E Allen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>biorxiv_medrxiv</td>\n",
       "      <td>https://doi.org/10.1101/010389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  vho70jcx  f056da9c64fbf00a4645ae326e8a4339d015d155  biorxiv   \n",
       "1  i9tbix2v  daf32e013d325a6feb80e83d15aabc64a48fae33  biorxiv   \n",
       "2  62gfisc6  f33c6d94b0efaa198f8f3f20e644625fa3fe10d2  biorxiv   \n",
       "3  058r9486  4da8a87e614373d56070ed272487451266dce919  biorxiv   \n",
       "4  wich35l7  eccef80cfbe078235df22398f195d5db462d8000  biorxiv   \n",
       "\n",
       "                                               title             doi pmcid  \\\n",
       "0  SIANN: Strain Identification by Alignment to N...  10.1101/001727   NaN   \n",
       "1  Spatial epidemiology of networked metapopulati...  10.1101/003889   NaN   \n",
       "2  Sequencing of the human IG light chain loci fr...  10.1101/006866   NaN   \n",
       "3  Bayesian mixture analysis for metagenomic comm...  10.1101/007476   NaN   \n",
       "4  Mapping a viral phylogeny onto outbreak trees ...  10.1101/010389   NaN   \n",
       "\n",
       "   pubmed_id  license                                           abstract  \\\n",
       "0        NaN  biorxiv  Next-generation sequencing is increasingly bei...   \n",
       "1        NaN  biorxiv  An emerging disease is one infectious epidemic...   \n",
       "2        NaN  biorxiv  Germline variation at immunoglobulin gene (IG)...   \n",
       "3        NaN  biorxiv  Deep sequencing of clinical samples is now an ...   \n",
       "4        NaN  biorxiv  Developing methods to reconstruct transmission...   \n",
       "\n",
       "  publish_time                                            authors journal  \\\n",
       "0   2014-01-10  Samuel Minot; Stephen D Turner; Krista L Ternu...     NaN   \n",
       "1   2014-06-04                                 Lin WANG; Xiang Li     NaN   \n",
       "2   2014-07-03  Corey T Watson; Karyn Meltz Steinberg; Tina A ...     NaN   \n",
       "3   2014-07-25                 Sofia Morfopoulou; Vincent Plagnol     NaN   \n",
       "4   2014-11-11                 Stephen P Velsko; Jonathan E Allen     NaN   \n",
       "\n",
       "   Microsoft Academic Paper ID WHO #Covidence  has_full_text   full_text_file  \\\n",
       "0                          NaN            NaN           True  biorxiv_medrxiv   \n",
       "1                          NaN            NaN           True  biorxiv_medrxiv   \n",
       "2                          NaN            NaN           True  biorxiv_medrxiv   \n",
       "3                          NaN            NaN           True  biorxiv_medrxiv   \n",
       "4                          NaN            NaN           True  biorxiv_medrxiv   \n",
       "\n",
       "                              url  \n",
       "0  https://doi.org/10.1101/001727  \n",
       "1  https://doi.org/10.1101/003889  \n",
       "2  https://doi.org/10.1101/006866  \n",
       "3  https://doi.org/10.1101/007476  \n",
       "4  https://doi.org/10.1101/010389  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file path: data >> news_data\n",
    "\"\"\"Table: news_article schema\n",
    "pk: cord_uid -> news_cord_uid\n",
    "1. source_x -> news_source\n",
    "    schema: StringType()\n",
    "2. title -> news_title\n",
    "    schema: StringType()\n",
    "3. license -> news_licence\n",
    "    schema: StringType()\n",
    "4. abstract -> news_abstract\n",
    "    schema: StringType()\n",
    "5. publish_time -> news_publish_time (fk)\n",
    "    schema: TimestampType()\n",
    "6. authors -> news_authors\n",
    "    schema: StringType()\n",
    "7. url -> news_url\n",
    "    schema: StringType()\n",
    "\"\"\"\n",
    "data_news = \"/Users/oneforall_nick/workspace/Udacity_capstone_project/airflow/data/news_data/metadata.csv\"\n",
    "\n",
    "df_news = pd.read_csv(data_news, header=0, delimiter=',')\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>Stockton</td>\n",
       "      <td>California</td>\n",
       "      <td>32.5</td>\n",
       "      <td>150976.0</td>\n",
       "      <td>154674.0</td>\n",
       "      <td>305650</td>\n",
       "      <td>12822.0</td>\n",
       "      <td>79583.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>19834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>Southfield</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>41.6</td>\n",
       "      <td>31369.0</td>\n",
       "      <td>41808.0</td>\n",
       "      <td>73177</td>\n",
       "      <td>4035.0</td>\n",
       "      <td>4011.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>MI</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>34.1</td>\n",
       "      <td>410615.0</td>\n",
       "      <td>437808.0</td>\n",
       "      <td>848423</td>\n",
       "      <td>42186.0</td>\n",
       "      <td>72456.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>IN</td>\n",
       "      <td>White</td>\n",
       "      <td>553665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>Somerville</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41028.0</td>\n",
       "      <td>39306.0</td>\n",
       "      <td>80334</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>22292.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>MA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>Coral Springs</td>\n",
       "      <td>Florida</td>\n",
       "      <td>37.2</td>\n",
       "      <td>63316.0</td>\n",
       "      <td>66186.0</td>\n",
       "      <td>129502</td>\n",
       "      <td>4724.0</td>\n",
       "      <td>38552.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>90896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  City          State  Median Age  Male Population  \\\n",
       "0        Silver Spring       Maryland        33.8          40601.0   \n",
       "1               Quincy  Massachusetts        41.0          44129.0   \n",
       "2               Hoover        Alabama        38.5          38040.0   \n",
       "3     Rancho Cucamonga     California        34.5          88127.0   \n",
       "4               Newark     New Jersey        34.6         138040.0   \n",
       "...                ...            ...         ...              ...   \n",
       "2886          Stockton     California        32.5         150976.0   \n",
       "2887        Southfield       Michigan        41.6          31369.0   \n",
       "2888      Indianapolis        Indiana        34.1         410615.0   \n",
       "2889        Somerville  Massachusetts        31.0          41028.0   \n",
       "2890     Coral Springs        Florida        37.2          63316.0   \n",
       "\n",
       "      Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0               41862.0             82463              1562.0       30908.0   \n",
       "1               49500.0             93629              4147.0       32935.0   \n",
       "2               46799.0             84839              4819.0        8229.0   \n",
       "3               87105.0            175232              5821.0       33878.0   \n",
       "4              143873.0            281913              5829.0       86253.0   \n",
       "...                 ...               ...                 ...           ...   \n",
       "2886           154674.0            305650             12822.0       79583.0   \n",
       "2887            41808.0             73177              4035.0        4011.0   \n",
       "2888           437808.0            848423             42186.0       72456.0   \n",
       "2889            39306.0             80334              2103.0       22292.0   \n",
       "2890            66186.0            129502              4724.0       38552.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "0                       2.60         MD                 Hispanic or Latino   \n",
       "1                       2.39         MA                              White   \n",
       "2                       2.58         AL                              Asian   \n",
       "3                       3.18         CA          Black or African-American   \n",
       "4                       2.73         NJ                              White   \n",
       "...                      ...        ...                                ...   \n",
       "2886                    3.16         CA  American Indian and Alaska Native   \n",
       "2887                    2.27         MI  American Indian and Alaska Native   \n",
       "2888                    2.53         IN                              White   \n",
       "2889                    2.43         MA  American Indian and Alaska Native   \n",
       "2890                    3.17         FL                              White   \n",
       "\n",
       "       Count  \n",
       "0      25924  \n",
       "1      58723  \n",
       "2       4759  \n",
       "3      24437  \n",
       "4      76402  \n",
       "...      ...  \n",
       "2886   19834  \n",
       "2887     983  \n",
       "2888  553665  \n",
       "2889     374  \n",
       "2890   90896  \n",
       "\n",
       "[2891 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file path: data >> usCitiesDemographics_data\n",
    "data_us_cities_demographics = \"/Users/oneforall_nick/workspace/Udacity_capstone_project/airflow/data/usCitiesDemographics_data/usCitiesDemo.csv\"\n",
    "\n",
    "df_data_us_cities_demographics = pd.read_csv(data_us_cities_demographics, header=0, delimiter=\";\")\n",
    "\n",
    "df_data_us_cities_demographics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------+-----------------------+-----------------+------------+---------+\n",
      "|cidemo_city|cidemo_state|cidemo_median_age|cidemo_total_population|cidemo_state_code|cidemo_count|cidemo_id|\n",
      "+-----------+------------+-----------------+-----------------------+-----------------+------------+---------+\n",
      "|       City|       State|             null|                   null|       Female ...|        null|        0|\n",
      "| Silver ...|    Maryland|             33.8|                  40601|            41862|       82463|        1|\n",
      "|     Quincy|  Massach...|             41.0|                  44129|            49500|       93629|        2|\n",
      "|     Hoover|     Alabama|             38.5|                  38040|            46799|       84839|        3|\n",
      "| Rancho ...|  California|             34.5|                  88127|            87105|      175232|        4|\n",
      "+-----------+------------+-----------------+-----------------------+-----------------+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a us-cities data dimension table\n",
    "\"\"\"Table: us_cities_demographics schema\n",
    "pk: generated -> cidemo_id\n",
    "    schema: IntegerType()\n",
    "1. City -> cidemo_city\n",
    "    schema: StringType()\n",
    "2. State -> cidemo_state\n",
    "    schema: StringType()\n",
    "3. Median Age -> cidemo_median_age\n",
    "    schema: FloatType()\n",
    "4. Total Population -> cidemo_total_population\n",
    "    schema: IntegerType()\n",
    "5. State Code -> cidemo_state_code (fk)\n",
    "    schema: StringType()\n",
    "6. Count -> cidemo_count\n",
    "    schema: IntegerType()\n",
    "\"\"\"\n",
    "\n",
    "# TODO -> Must be defined a function that generated each table schema:\n",
    "new_data_schema = StructType([\\\n",
    "    StructField(name=\"cidemo_city\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"cidemo_state\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"cidemo_median_age\", dataType=FloatType(), nullable=True),\n",
    "    StructField(name=\"cidemo_total_population\", dataType=IntegerType(), nullable=True),\n",
    "    StructField(name=\"cidemo_state_code\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"cidemo_count\", dataType=IntegerType(), nullable=True)\n",
    "])\n",
    "\n",
    "# Using pyspark to read csv file\n",
    "pdf_news = spark.read.options(delimiter=';').csv(data_us_cities_demographics, schema=new_data_schema)\n",
    "# pdf_news.printSchema()\n",
    "\"\"\"\n",
    "root\n",
    " |-- cidemo_city: string (nullable = true)\n",
    " |-- cidemo_state: string (nullable = true)\n",
    " |-- cidemo_median_age: float (nullable = true)\n",
    " |-- cidemo_total_population: integer (nullable = true)\n",
    " |-- cidemo_state_code: string (nullable = true)\n",
    " |-- cidemo_count: integer (nullable = true)\n",
    "\"\"\"\n",
    "# Auto-generated series of id\n",
    "pdf_news = pdf_news.withColumn(\"cidemo_id\", monotonically_increasing_id())\n",
    "pdf_news.show(n=5, truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This code block is be placed in analysis jupyter notebook files\n",
    "imm_data = \"/Users/oneforall_nick/workspace/Udacity_capstone_project/airflow/data/immigration_data/immigration_apr16_sub.sas7bdat\"\n",
    "\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Using the library for knowing more data information\n",
    "# TODO: chunksize??Iteraters??\n",
    "# imm_data_read = SAS7BDAT(imm_data)\n",
    "\n",
    "# imm_data_read.header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data column attributes\n",
    "# for i in imm_data_read.columns:\n",
    "#     print(\"col_id \", i.col_id)\n",
    "#     print(\"  name\",  i.name.decode(encoding ='utf-8'))\n",
    "#     print(\"  label\", i.label.decode(encoding ='utf-8'))\n",
    "#     print(\"  format\", i.format)\n",
    "#     print(\"  type\", i.type)\n",
    "#     print(\"  length\", i.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Dealing with multiple data files\n",
    "# TODO: Make a def for doing this.\n",
    "# Method1: Using pandas to read file.\n",
    "pdf_immigration = pd.read_sas(imm_data, format='sas7bdat', iterator=True, chunksize=5000000)\n",
    "# pdf_immigration = pd.read_sas(imm_data, format='sas7bdat')\n",
    "\n",
    "imm_chunks_1 = list(pdf_immigration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_chunks_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# imm_chunks_1[['cicid', 'biryear', 'gender', 'visatype']]\n",
    "# imm_chunks_1[:]\n",
    "imm_person = []\n",
    "for data in imm_chunks_1:\n",
    "    imm_person.append(data[['cicid', 'biryear', 'gender', 'visatype']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>biryear</th>\n",
       "      <th>gender</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'F1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>58710.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>b'F'</td>\n",
       "      <td>b'WT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>58711.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'WT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>58712.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'WB'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>58713.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'WT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>58714.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>b'WT'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cicid  biryear gender visatype\n",
       "0          6.0   1979.0    NaN    b'B2'\n",
       "1          7.0   1991.0   b'M'    b'F1'\n",
       "2         15.0   1961.0   b'M'    b'B2'\n",
       "3         16.0   1988.0    NaN    b'B2'\n",
       "4         17.0   2012.0    NaN    b'B2'\n",
       "...        ...      ...    ...      ...\n",
       "49995  58710.0   1958.0   b'F'    b'WT'\n",
       "49996  58711.0   1967.0   b'M'    b'WT'\n",
       "49997  58712.0   1970.0   b'M'    b'WB'\n",
       "49998  58713.0   1971.0   b'M'    b'WT'\n",
       "49999  58714.0   1971.0   b'M'    b'WT'\n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "imm_person[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using rdd to read data.\n",
    "# rdd = spark.sparkContext.parallelize(imm_chunks_1)\n",
    "type(pdf_immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.sas.sas7bdat import SAS7BDATReader\n",
    "\n",
    "rdr = SAS7BDATReader(imm_data, convert_header_text=False)\n",
    "df3 = rdr.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b'cicid'</th>\n",
       "      <th>b'i94yr'</th>\n",
       "      <th>b'i94mon'</th>\n",
       "      <th>b'i94cit'</th>\n",
       "      <th>b'i94res'</th>\n",
       "      <th>b'i94port'</th>\n",
       "      <th>b'arrdate'</th>\n",
       "      <th>b'i94mode'</th>\n",
       "      <th>b'i94addr'</th>\n",
       "      <th>b'depdate'</th>\n",
       "      <th>...</th>\n",
       "      <th>b'entdepu'</th>\n",
       "      <th>b'matflag'</th>\n",
       "      <th>b'biryear'</th>\n",
       "      <th>b'dtaddto'</th>\n",
       "      <th>b'gender'</th>\n",
       "      <th>b'insnum'</th>\n",
       "      <th>b'airline'</th>\n",
       "      <th>b'admnum'</th>\n",
       "      <th>b'fltno'</th>\n",
       "      <th>b'visatype'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>b'XXX'</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>b'10282016'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>b'ATL'</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'AL'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>b'D/S'</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>b'00296'</td>\n",
       "      <td>b'F1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>b'WAS'</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'MI'</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>b'09302016'</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'OS'</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>b'93'</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>b'NYC'</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'MA'</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>b'09302016'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'AA'</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>b'00199'</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>b'NYC'</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'MA'</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'M'</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>b'09302016'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'AA'</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>b'00199'</td>\n",
       "      <td>b'B2'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b'cicid'  b'i94yr'  b'i94mon'  b'i94cit'  b'i94res' b'i94port'  b'arrdate'  \\\n",
       "0       6.0    2016.0        4.0      692.0      692.0     b'XXX'     20573.0   \n",
       "1       7.0    2016.0        4.0      254.0      276.0     b'ATL'     20551.0   \n",
       "2      15.0    2016.0        4.0      101.0      101.0     b'WAS'     20545.0   \n",
       "3      16.0    2016.0        4.0      101.0      101.0     b'NYC'     20545.0   \n",
       "4      17.0    2016.0        4.0      101.0      101.0     b'NYC'     20545.0   \n",
       "\n",
       "   b'i94mode' b'i94addr'  b'depdate'  ...  b'entdepu'  b'matflag'  b'biryear'  \\\n",
       "0         NaN        NaN         NaN  ...        b'U'         NaN      1979.0   \n",
       "1         1.0      b'AL'         NaN  ...        b'Y'         NaN      1991.0   \n",
       "2         1.0      b'MI'     20691.0  ...         NaN        b'M'      1961.0   \n",
       "3         1.0      b'MA'     20567.0  ...         NaN        b'M'      1988.0   \n",
       "4         1.0      b'MA'     20567.0  ...         NaN        b'M'      2012.0   \n",
       "\n",
       "    b'dtaddto' b'gender' b'insnum' b'airline'     b'admnum'  b'fltno'  \\\n",
       "0  b'10282016'       NaN       NaN        NaN  1.897628e+09       NaN   \n",
       "1       b'D/S'      b'M'       NaN        NaN  3.736796e+09  b'00296'   \n",
       "2  b'09302016'      b'M'       NaN      b'OS'  6.666432e+08     b'93'   \n",
       "3  b'09302016'       NaN       NaN      b'AA'  9.246846e+10  b'00199'   \n",
       "4  b'09302016'       NaN       NaN      b'AA'  9.246846e+10  b'00199'   \n",
       "\n",
       "  b'visatype'  \n",
       "0       b'B2'  \n",
       "1       b'F1'  \n",
       "2       b'B2'  \n",
       "3       b'B2'  \n",
       "4       b'B2'  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd.take(7)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_person = df3[[b'cicid', b'biryear', b'gender', b'visatype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"imm_per_cic_id\", dataType=FloatType(), nullable=False),\n",
    "    StructField(\"imm_person_birth_year\", dataType=FloatType(), nullable=True),\n",
    "    StructField(\"imm_person_gender\", dataType=StringType(), nullable=True),\n",
    "    StructField(\"imm_person_visa_type\", dataType=StringType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = spark.createDataFrame(imm_person, schema=schema)\n",
    "# imm_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- imm_per_cic_id: float (nullable = false)\n",
      " |-- imm_person_birth_year: float (nullable = true)\n",
      " |-- imm_person_gender: string (nullable = true)\n",
      " |-- imm_person_visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf.show(n=1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48f95af79faaae749105c8389524df19196568350894b01545e0b6f755f2644b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('udacity_capstone_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
