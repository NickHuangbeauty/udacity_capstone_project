[
    {
        "Name": "Upload sas jars file from local to aws s3",
        "ActionOnFailure": "CONTINUE",
        "HadoopJarStep": {
            // TODO:Set bootstrap_bucket in Airflow variables
            // TODO: Upload data_spark_on_emr.py from local to AWS S3
            // Using spark-summit to execute the data_spark_on_emr python file for dealing with data.
            "Jar": "command-runner.jar",
            "Args":[
                "s3-dist-cp",
                // variable set: upload_data/jars/
                "--src=s3://{{ var.value.sas_jars_bucket }}/spark-sas7bdat-3.0.0-s_2.12.jar",
                "--dest=/usr/lib/spark/jars"
            ]
        }
    },
    {
        "Name": "For Dealing with data and analytics using Spark on AWS EMR",
        "ActionOnFailure": "CANCEL_AND_WAIT",
        "HadoopJarStep": {
            // TODO:Set bootstrap_bucket in Airflow variables
            // Using spark-summit to execute the data_spark_on_emr python file for dealing with data.
            "Jar": "command-runner.jar",
            "Args":[
                "Spark-Submit",
                "--master",
                "yarn",
                "--deploy-mode",
                "cluster",
                "--name",
                "data_spark_on_emr",
                "s3://{{ var.value.bootstrap_bucket }}/data_spark_on_emr.py"
            ]
        }
    }
]
